{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная обучение без учителя\n",
    "\n",
    "Лабораторная состоит из гайда по работе с задачами машинного обучения без учителя (unsupervised learning) на Python и нескольких заданий:\n",
    "* [Задание 1](#Задание-1.) - понижение размерности с помощью t-SNE;\n",
    "* [Задание 2](#Задание-2.) - кластеризация с фильтрацией выбросов с помощью DBSCAN;\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Необходимые модули\n",
    "\n",
    "Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Понижение размерности\n",
    "\n",
    "Одна из задач обучения без учителя (unsupervised learning) - понижение размерности.\n",
    "\n",
    "Напомним, что идея задачи понижения размерности состоит в переходе к небольшому числу показательных (информативных) признаков, принимающих много значений - с такими признаками работать проще.\n",
    "\n",
    "Воспользуемся методом t-SNE для понижения размерности для данных \"wine\" (набор данных доступен в библиотеке scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прочитаем данные\n",
    "x_all, y_all = load_iris(return_X_y=True)\n",
    "# Поделим на тренировочную и тестовую выборки\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Размеры выборок: тренировочная - {x_train.shape[0]}, тестовая - {x_test.shape[0]}')\n",
    "print(f'Кол-во признаков: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор, основанный на _машине опорных векторов_ (support vector machine, SVM).\n",
    "\n",
    "Метод SVM ищет параметры гиперплоскости (или гиперповерхности), которая разделяет пространство признаков данных на области, каждая область соответствует своему классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sv_clf.predict(x_test)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся t-SNE в качестве предобработки данных\n",
    "\n",
    "_Примечание:_ особенность метода t-SNE и его реализации в scikit-learn в том, что этот метод нельзя применять к новым данным, которые могут появиться на стадии предсказания обученной модели. Появление новых данных может серьёзно изменить отображение, построенное с помощью t-SNE, что является серьёзным ограничением применимости этого метода. В связи с этим, отображение t-SNE следует строить сразу и для тренировочных, и для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='random', random_state=123)\n",
    "# Так как строим отображение сразу и для тренировочных, и для тестовых данных, надо запомнить, какие из данных тренировочные\n",
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]  # Вытаскиваем признаки для тренировочных данных\n",
    "x_test_transformed = x_all_transformed[train_len:, :]  # Остальные данные - тестовые\n",
    "print(f'Кол-во признаков после предобработки: {x_train_transformed.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация данных после предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tsne_result(x_train_new, x_test_new, y_train, y_test):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    ax[0].scatter(x_train_new[:,0], x_train_new[:,1], c=y_train)\n",
    "    ax[0].set_title('Train')\n",
    "    \n",
    "    ax[1].scatter(x_test_new[:,0], x_test_new[:,1], c=y_test)\n",
    "    ax[1].set_title('Test')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим SVM-классификатор с линейным ядром и посмотрим, как улучшилось качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите параметры `TSNE` так, чтобы SVM-классификатор с линейным ядром, обученный на предобработанных данных, давал качество по **каждой** из метрик `accuracy` и `f1` **не ниже** `0.98`. При этом параметр `n_components` оставьте равным `2`.\n",
    "\n",
    "Менять можно **только** параметры `t-SNE`, менять гиперпараметры SVM-классификатора **запрещается**.\n",
    "\n",
    "_Подсказки_:\n",
    "1. Наиболее важный параметр в методе t-SNE - `perplexity`.\n",
    "2. SVM с линейным ядром идеально работает, когда данные линейно разделимы - то есть, когда для каждого класса есть прямая (в нашем случае), отделяющая этот класс от остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте параметры в TSNE\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # но кол-во размерностей оставьте равным 2\n",
    "    init='random',\n",
    "    random_state=123,\n",
    "    perplexity=30.0,\n",
    ")\n",
    "\n",
    "# Код для предобработки менять можно, но не обязательно\n",
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]\n",
    "x_test_transformed = x_all_transformed[train_len:, :]\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)\n",
    "\n",
    "# Код ниже менять запрещается\n",
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "final_accuracy, final_f1 = accuracy_score(y_test, predictions), f1_score(y_test, predictions, average='macro')\n",
    "print('Accuracy score = {:.3f}'.format(final_accuracy))\n",
    "print('F1 score = {:.3f}'.format(final_f1))\n",
    "if final_accuracy >= 0.98 and final_f1 >= 0.98:\n",
    "    print('Требуемое качество достигнуто')\n",
    "else:\n",
    "    print('Требуемое качество не достигнуто')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Кластеризация\n",
    "\n",
    "### K-Means\n",
    "\n",
    "На практике случается, что надо объединить данные в группы, при этом известно количество групп. Такую задачу можно решить с помощью метода кластеризации _K-Means_ (или K-средних).\n",
    "\n",
    "Метод пытается найти такие \"центры\" кластеров, чтобы минимизировать СКО внутри кластеров.\n",
    "\n",
    "Особенности метода:\n",
    "* Требуется задать кол-во кластеров\n",
    "* Требуется задать начальное положение всех центров\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные, посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blobs, y_blobs = make_blobs(n_samples=100, centers=3, n_features=2, random_state=1234)  # Лучше не менять random_state\n",
    "\n",
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=y_blobs)\n",
    "plt.title('Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По картинке видно, что данные образуют 3 группы.\n",
    "\n",
    "Воспользуемся методом K-means, чтобы разделить данные на группы, не пользуясь информацией о метках\n",
    "\n",
    "_Замечание_: обычно начальное положение центров кластеров задаются случайным образом, как и в случае метода `KMeans` из библиотеки scikit-learn, который использован далее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=3, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выполнена кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 3)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что будет, если с помощью параметра `n_clusters` задать не 3, а 4 кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=4, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 4)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `K-means` имеет свои особенности, из-за которых она применима в задачах, где известно кол-во кластеров, и эти кластеры можно описывать шарами (это заложено в принцип обучения модели).\n",
    "\n",
    "Если \"контекст\", в котором ставится задача кластеризации, подразумевает, что кластерам могут соответствовать области более сложной формы, или неизвестно кол-во кластеров, следует пользоваться другими методами.\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "Рассмотрим подробнее метод кластеризации _DBSCAN_.\n",
    "\n",
    "Особенности этого метода:\n",
    "* Кластерами считаются такие облака из точек, где точки находятся _достаточно близко_ друг к другу - можно находить плотные кластеры более сложной формы, чем простые шары\n",
    "* Точки, у которых \"нет соседей\", можно считать выбросами\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные в виде прямоугольной области и \"кольца\" около этой области"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "cluster_1 = np.random.uniform(-2, 2, (300, 2))\n",
    "\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, 350)\n",
    "cluster_2_r = np.random.uniform(4, 5, 350)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "clusters = np.vstack([cluster_1, cluster_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters[:,0], clusters[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кластеризацию с помощью `KMeans` и `DBSCAN`.\n",
    "\n",
    "Ожидаем, что KMeans не сможет отличить кольцо от прямоугольника, а DBSCAN сможет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=123).fit(clusters)\n",
    "dbscan = DBSCAN(eps=1, min_samples=10).fit(clusters)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "for i, (method, name) in enumerate(zip((kmeans, dbscan), (\"KMeans\", \"DBSCAN\"))):\n",
    "    ax[i].scatter(clusters[:,0], clusters[:,1], c=method.labels_)\n",
    "    ax[i].set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим случайный шум (распределённый равномерно, но не плотно), чтобы имитировать выбросы.\n",
    "\n",
    "Чуть повысим плотность объектов в \"кольце\", повысив их кол-во"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "cluster_1 = np.random.uniform(-2, 2, (300, 2))\n",
    "\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, 450)\n",
    "cluster_2_r = np.random.uniform(4, 5, 450)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "outliers = np.random.uniform(-6, 6, (40, 2))\n",
    "\n",
    "clusters = np.vstack([cluster_1, cluster_2, outliers])\n",
    "\n",
    "plt.scatter(clusters[:,0], clusters[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Задание 2.\n",
    "\n",
    "Произведите кластеризацию таким образом, чтобы \"выбросы\" были зафиксированы, но при этом кластеры \"не распадались\" на более мелкие компоненты. Следует подбирать **следующие параметры**: `eps`, `min_samples`.\n",
    "\n",
    "Ответ состоит из одной картинки с двумя \"подграфиками\":\n",
    "* на подграфике \"All\" должны быть показаны результаты кластеризации (должно получиться 2 кластера и выбросы)\n",
    "* на подграфике \"No outliers\" должны быть показаны те же результаты кластеризации, но выбросы должны быть отфильтрованы\n",
    "\n",
    "Сохраните полученную картинку в файл `task_2.png`.\n",
    "\n",
    "**Важно**: кластеры остаются теми же - квадрат в области $[-2,2]^2$ и кольцо около этого квадрата. Менять данные запрещается!\n",
    "\n",
    "_Подсказка_: чтобы кластер не распадался на множество кластеров, можно уменьшать `eps`; чтобы несколько стоящих рядом выбросов не объединялись в целый кластер, можно увеличивать `min_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следует поменять параметры только у конструктора класса DBSCAN\n",
    "dbscan = DBSCAN(eps=1, min_samples=10).fit(clusters)\n",
    "\n",
    "# Код ниже нужен только для отрисовки, его менять не надо\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "ax[0].scatter(clusters[:,0], clusters[:,1], c=dbscan.labels_)\n",
    "ax[0].set_title('All')\n",
    "\n",
    "clusters_no_outliers = clusters[dbscan.labels_ != -1,:]\n",
    "ax[1].scatter(clusters_no_outliers[:,0], clusters_no_outliers[:,1], c=dbscan.labels_[dbscan.labels_ != -1])\n",
    "ax[1].set_title('No outliers')\n",
    "\n",
    "plt.savefig('task_2.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
