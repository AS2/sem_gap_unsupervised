{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная обучение без учителя\n",
    "\n",
    "Лабораторная состоит из гайда по работе с задачами машинного обучения без учителя (unsupervised learning) на Python и трёх обязательных заданий:\n",
    "* [Задание 1](#Задание-1.) - понижение размерности с помощью t-SNE;\n",
    "* [Задание 2](#Задание-2.) - кластеризация с фильтрацией выбросов с помощью DBSCAN;\n",
    "* [Задание 3](#Задание-3.) - кластеризация вершин графа генов _Mus musculus_ с помощью MCL. За попадание в топ 3 по качеству кластеризации можно получить 1 дополнительный балл.\n",
    "\n",
    "Сначала рекомендуется ознакомиться с гайдом, после чего выполнять задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Необходимые модули\n",
    "\n",
    "Подключим необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cluster import KMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Понижение размерности\n",
    "\n",
    "Одна из задач обучения без учителя (unsupervised learning) - понижение размерности.\n",
    "\n",
    "Напомним, что идея задачи понижения размерности состоит в переходе к небольшому числу показательных (информативных) признаков, принимающих много значений - с такими признаками работать проще.\n",
    "\n",
    "Воспользуемся методом t-SNE для понижения размерности для данных \"wine\" (набор данных доступен в библиотеке scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Прочитаем данные\n",
    "x_all, y_all = load_iris(return_X_y=True)\n",
    "# Поделим на тренировочную и тестовую выборки\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Размеры выборок: тренировочная - {x_train.shape[0]}, тестовая - {x_test.shape[0]}')\n",
    "print(f'Кол-во признаков: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим классификатор, основанный на _машине опорных векторов_ (support vector machine, SVM).\n",
    "\n",
    "Метод SVM ищет параметры гиперплоскости (или гиперповерхности), которая разделяет пространство признаков данных на области, каждая область соответствует своему классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим качество полученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = sv_clf.predict(x_test)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся t-SNE в качестве предобработки данных\n",
    "\n",
    "_Примечание:_ особенность метода t-SNE и его реализации в scikit-learn в том, что этот метод нельзя применять к новым данным, которые могут появиться на стадии предсказания обученной модели. Появление новых данных может серьёзно изменить отображение, построенное с помощью t-SNE, что является серьёзным ограничением применимости этого метода. В связи с этим, отображение t-SNE следует строить сразу и для тренировочных, и для тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='random', random_state=123)\n",
    "# Так как строим отображение сразу и для тренировочных, и для тестовых данных, надо запомнить, какие из данных тренировочные\n",
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]  # Вытаскиваем признаки для тренировочных данных\n",
    "x_test_transformed = x_all_transformed[train_len:, :]  # Остальные данные - тестовые\n",
    "print(f'Кол-во признаков после предобработки: {x_train_transformed.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализация данных после предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tsne_result(x_train_new, x_test_new, y_train, y_test):\n",
    "    fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "    ax[0].scatter(x_train_new[:,0], x_train_new[:,1], c=y_train)\n",
    "    ax[0].set_title('Train')\n",
    "    \n",
    "    ax[1].scatter(x_test_new[:,0], x_test_new[:,1], c=y_test)\n",
    "    ax[1].set_title('Test')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим SVM-классификатор с линейным ядром и посмотрим, как улучшилось качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "print('Accuracy score = {:.3f}'.format(accuracy_score(y_test, predictions)))\n",
    "print('F1 score = {:.3f}'.format(f1_score(y_test, predictions, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "Подберите параметры `TSNE` так, чтобы SVM-классификатор с линейным ядром, обученный на предобработанных данных, давал качество по **каждой** из метрик `accuracy` и `f1` **не ниже** `0.98`. При этом параметр `n_components` оставьте равным `2`.\n",
    "\n",
    "Менять можно **только** параметры `t-SNE`, менять гиперпараметры SVM-классификатора **запрещается**.\n",
    "\n",
    "_Подсказки_:\n",
    "1. Наиболее важный параметр в методе t-SNE - `perplexity`.\n",
    "2. SVM с линейным ядром идеально работает, когда данные линейно разделимы - то есть, когда для каждого класса есть прямая (в нашем случае), отделяющая этот класс от остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поменяйте параметры в TSNE\n",
    "tsne = TSNE(\n",
    "    n_components=2,  # но кол-во размерностей оставьте равным 2\n",
    "    init='random',\n",
    "    random_state=123,\n",
    "    perplexity=30.0,\n",
    ")\n",
    "\n",
    "# Код для предобработки менять можно, но не обязательно\n",
    "train_len = x_train.shape[0]\n",
    "x_all_transformed = tsne.fit_transform(np.vstack([x_train, x_test]))\n",
    "x_train_transformed = x_all_transformed[:train_len, :]\n",
    "x_test_transformed = x_all_transformed[train_len:, :]\n",
    "\n",
    "show_tsne_result(x_train_transformed, x_test_transformed, y_train, y_test)\n",
    "\n",
    "# Код ниже менять запрещается\n",
    "sv_clf = SVC(kernel='linear', random_state=123)\n",
    "sv_clf.fit(x_train_transformed, y_train)\n",
    "predictions = sv_clf.predict(x_test_transformed)\n",
    "final_accuracy, final_f1 = accuracy_score(y_test, predictions), f1_score(y_test, predictions, average='macro')\n",
    "print('Accuracy score = {:.3f}'.format(final_accuracy))\n",
    "print('F1 score = {:.3f}'.format(final_f1))\n",
    "if final_accuracy >= 0.98 and final_f1 >= 0.98:\n",
    "    print('Требуемое качество достигнуто')\n",
    "else:\n",
    "    print('Требуемое качество не достигнуто')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Кластеризация\n",
    "\n",
    "### K-Means\n",
    "\n",
    "На практике случается, что надо объединить данные в группы, при этом известно количество групп. Такую задачу можно решить с помощью метода кластеризации _K-Means_ (или K-средних).\n",
    "\n",
    "Метод пытается найти такие \"центры\" кластеров, чтобы минимизировать СКО внутри кластеров.\n",
    "\n",
    "Особенности метода:\n",
    "* Требуется задать кол-во кластеров\n",
    "* Требуется задать начальное положение всех центров\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные, посмотрим на них"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_blobs, y_blobs = make_blobs(n_samples=100, centers=3, n_features=2, random_state=1234)  # Лучше не менять random_state\n",
    "\n",
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=y_blobs)\n",
    "plt.title('Clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По картинке видно, что данные образуют 3 группы.\n",
    "\n",
    "Воспользуемся методом K-means, чтобы разделить данные на группы, не пользуясь информацией о метках\n",
    "\n",
    "_Замечание_: обычно начальное положение центров кластеров задаются случайным образом, как и в случае метода `KMeans` из библиотеки scikit-learn, который использован далее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=3, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как выполнена кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 3)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что будет, если с помощью параметра `n_clusters` задать не 3, а 4 кластера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=4, random_state=123)\n",
    "kmeans_clustering.fit(x_blobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_blobs[:,0], x_blobs[:,1], c=kmeans_clustering.labels_)\n",
    "plt.title('Clustering with K-Means (K = 4)')\n",
    "\n",
    "cluster_centers = kmeans_clustering.cluster_centers_\n",
    "\n",
    "# Красными точками отметим центры кластеров\n",
    "plt.plot(cluster_centers[:,0], cluster_centers[:,1], 'ro', markersize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель `K-means` имеет свои особенности, из-за которых она применима в задачах, где известно кол-во кластеров, и эти кластеры можно описывать шарами (это заложено в принцип обучения модели).\n",
    "\n",
    "Если \"контекст\", в котором ставится задача кластеризации, подразумевает, что кластерам могут соответствовать области более сложной формы, или неизвестно кол-во кластеров, следует пользоваться другими методами.\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "Рассмотрим подробнее метод кластеризации _DBSCAN_.\n",
    "\n",
    "Особенности этого метода:\n",
    "* Кластерами считаются такие облака из точек, где точки находятся _достаточно близко_ друг к другу - можно находить плотные кластеры более сложной формы, чем простые шары\n",
    "* Точки, у которых \"нет соседей\", можно считать выбросами\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Сгенерируем данные в виде прямоугольной области и \"кольца\" около этой области"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "cluster_1 = np.random.uniform(-2, 2, (300, 2))\n",
    "\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, 350)\n",
    "cluster_2_r = np.random.uniform(4, 5, 350)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "clusters = np.vstack([cluster_1, cluster_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters[:,0], clusters[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим кластеризацию с помощью `KMeans` и `DBSCAN`.\n",
    "\n",
    "Ожидаем, что KMeans не сможет отличить кольцо от прямоугольника, а DBSCAN сможет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=123).fit(clusters)\n",
    "dbscan = DBSCAN(eps=1, min_samples=10).fit(clusters)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "for i, (method, name) in enumerate(zip((kmeans, dbscan), (\"KMeans\", \"DBSCAN\"))):\n",
    "    ax[i].scatter(clusters[:,0], clusters[:,1], c=method.labels_)\n",
    "    ax[i].set_title(name)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим случайный шум (распределённый равномерно, но не плотно), чтобы имитировать выбросы.\n",
    "\n",
    "Чуть повысим плотность объектов в \"кольце\", повысив их кол-во"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "cluster_1 = np.random.uniform(-2, 2, (300, 2))\n",
    "\n",
    "cluster_2_phi = np.random.uniform(-np.pi, np.pi, 450)\n",
    "cluster_2_r = np.random.uniform(4, 5, 450)\n",
    "cluster_2_x, cluster_2_y = cluster_2_r * np.cos(cluster_2_phi), cluster_2_r * np.sin(cluster_2_phi)\n",
    "cluster_2 = np.vstack([cluster_2_x, cluster_2_y]).transpose(1, 0)\n",
    "\n",
    "outliers = np.random.uniform(-6, 6, (40, 2))\n",
    "\n",
    "clusters = np.vstack([cluster_1, cluster_2, outliers])\n",
    "\n",
    "plt.scatter(clusters[:,0], clusters[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Задание 2.\n",
    "\n",
    "Произведите кластеризацию таким образом, чтобы \"выбросы\" были зафиксированы, но при этом кластеры \"не распадались\" на более мелкие компоненты. Следует подбирать **следующие параметры**: `eps`, `min_samples`.\n",
    "\n",
    "Ответ состоит из одной картинки с двумя \"подграфиками\":\n",
    "* на подграфике \"All\" должны быть показаны результаты кластеризации (должно получиться 2 кластера и выбросы)\n",
    "* на подграфике \"No outliers\" должны быть показаны те же результаты кластеризации, но выбросы должны быть отфильтрованы\n",
    "\n",
    "Сохраните полученную картинку в файл `task_2.png`.\n",
    "\n",
    "**Важно**: кластеры остаются теми же - квадрат в области $[-2,2]^2$ и кольцо около этого квадрата. Менять данные запрещается!\n",
    "\n",
    "_Подсказка_: чтобы кластер не распадался на множество кластеров, можно уменьшать `eps`; чтобы несколько стоящих рядом выбросов не объединялись в целый кластер, можно увеличивать `min_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следует поменять параметры только у конструктора класса DBSCAN\n",
    "dbscan = DBSCAN(eps=1, min_samples=10).fit(clusters)\n",
    "\n",
    "# Код ниже нужен только для отрисовки, его менять не надо\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(15, 5))\n",
    "\n",
    "ax[0].scatter(clusters[:,0], clusters[:,1], c=dbscan.labels_)\n",
    "ax[0].set_title('All')\n",
    "\n",
    "clusters_no_outliers = clusters[dbscan.labels_ != -1,:]\n",
    "ax[1].scatter(clusters_no_outliers[:,0], clusters_no_outliers[:,1], c=dbscan.labels_[dbscan.labels_ != -1])\n",
    "ax[1].set_title('No outliers')\n",
    "\n",
    "plt.savefig('task_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### MCL-clustering\n",
    "\n",
    "Еще один интересный алгоритм кластеризации - _MCL algorithm - Markov Cluster Algorithm_ на основе графов.\n",
    "\n",
    "Метод опирается на следующие утверджения:\n",
    "* Расстояние между узлами графа, относящимися к одному кластеру, меньше, чем расстояниме между узлами, относящимися к различным кластерам\n",
    "* При случайном обходе графа, прежде чем покинуть кластер, будут посещены многие из его вершин\n",
    "* Края между кластерами вероятнее всего находятся на кратчайших путях\n",
    "\n",
    "Особенности метода:\n",
    "\n",
    "* Может работать с взвешенными и невзвешенными графами\n",
    "* Может находить кластеры произвольной формы\n",
    "* Не умеет находить перекрывающиеся кластеры\n",
    "* Кластеры могут быть разного размера\n",
    "\n",
    "Подробнее можно прочитать тут: https://micans.org/mcl/\n",
    "\n",
    "Для того, чтобы воспользоваться алгоритмом, дополнительно установим библиотеку `markov-clustering`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install markov-clustering\n",
    "!pip install decorator==5.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример\n",
    "\n",
    "Посмотрим, как алгоритм будет работать на модельных данных. Сгенерируем случайный граф с помощью библиотеки `networkx`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "# задаем нужное количество вершин\n",
    "nodesnum = 50\n",
    "\n",
    "# генерируем граф\n",
    "graph = nx.random_geometric_graph(nodesnum, radius = 0.3)\n",
    "\n",
    "# получаем матрицу смежности из сгенерированного графа\n",
    "matrix = nx.to_scipy_sparse_matrix(graph)\n",
    "\n",
    "# получаем расположение узлов сгенерированного графа\n",
    "positions = nx.spring_layout(graph)\n",
    "\n",
    "#нарисуем получившийся граф\n",
    "nx.draw(graph, pos = positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим марковский алгоритм кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import markov_clustering as mc\n",
    "\n",
    "# получаем результат кластеризации\n",
    "result = mc.run_mcl(matrix)\n",
    "\n",
    "# выделяем получившиеся кластеры\n",
    "clusters = mc.get_clusters(result)\n",
    "\n",
    "# отрисовываем граф с результатами кластеризации\n",
    "mc.draw_graph(matrix, clusters, pos = positions, with_labels = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одной из наиболее популярных метрик оценки качества кластеризации на графах является __модулярность__.\n",
    "\n",
    "Модулярность представляет собой меру \"неслучайности\" полученных кластеров.\n",
    "\n",
    "Пусть $k_i$ - степень вершины $i$,  \n",
    "$m$ - число ребер в графе,  \n",
    "$A$ - матрица смежности, содержащая веса ребер,  \n",
    "$c_i$ - кластер, к которому относится вершина $i$,  \n",
    "$\\delta(i,j) = 1$ при $c_i=c_j$, иначе $0$.  \n",
    "Допустим, мы перемещаем ребра, сохраняя распределение степеней. Тогда грубая оценка вероятности того, что $i$ и $j$ будут соединены, равняется: $\\cfrac{k_ik_j}{2m}$.\n",
    "\n",
    "Тогда __модулярность__ - мера \"неслучайнсости\" - рассчитывается следующим образом:\n",
    "$$Q = \\cfrac{1}{2m}\\sum_{i, j}\\left[A_{i, j} - \\cfrac{k_ik_j}{2m}\\right]\\delta(c_i, c_j)$$\n",
    "\n",
    "Чем выше значение величины модулярности, тем лучше качество кластеризации. Модулярность лежит в интервале от $-1$ до $1$.\n",
    "\n",
    "Посчитаем модулярность нашего варианта кластеризации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mc.modularity(matrix = result, clusters = clusters)\n",
    "print('Modularity score = {:.3f}'.format(Q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим [данные](https://www.omicsdi.org/dataset/geo/GSE10246) об эксперссии генов мышей. Был построен граф генов _Mus musculus_, где вершинами являются сами гены, а взвешенные ребра показывают отношение их коэкспрессии друг к другу.   \n",
    "Загрузим получившийся граф и посмотрим на него:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "# считываем датасет\n",
    "G = pd.read_csv(\"task3.csv\", sep=\";\", header=None)\n",
    "\n",
    "# создаем граф\n",
    "graph = nx.Graph()\n",
    "\n",
    "for i in range(len(G)):\n",
    "    graph.add_edge(G[0][i], G[1][i], weight = G[2][i])\n",
    "\n",
    "# получаем матрицу смежности для данного графа\n",
    "matr = nx.to_scipy_sparse_matrix(graph)\n",
    "\n",
    "# получаем расположение узлов графа генов\n",
    "p = nx.spring_layout(graph, seed=123)\n",
    " \n",
    "# отрисовываем граф\n",
    "nx.draw(graph, pos=p, node_size=50, edge_color=\"silver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "Проведите кластеризацию с помощью марковского алгоритма так, чтобы модулярность оказалась выше `0.796`.\n",
    "\n",
    "Для этого изменяйте параметры алгоритма - функции `run_mcl`.\n",
    "\n",
    "_Наиболее важные параметры:_\n",
    "* `expansion > 1`, целое - \"расширение\" матрицы - то есть степень, в которую будет возводиться матрица смежности\n",
    "* `inflation > 1`, вещественное - \"инфляция\" матрицы - то есть степень, в которую будет возведен каждый элемент матрицы\n",
    "\n",
    "Другие параметры:\n",
    "* `loop_value >=0` - значение, присваемое в матрице смежности для переходов из вершины в саму себя\n",
    "* `iterations > 0` - количество итераций алгоритма. Если будет достигнута сходимость, итераций может быть меньше указанных\n",
    "* `pruning_treshold >= 0` - если значение в матрице становится меньше данного, оно заменяется на 0\n",
    "\n",
    "_За попадание в топ 3 по качеству в этой задаче можно получить 1 дополнительный балл_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mc.run_mcl(matr,\n",
    "                 # Эти параметры можно менять\n",
    "                 expansion=2,\n",
    "                 inflation=2,\n",
    "                 loop_value=1,\n",
    "                 iterations=100,\n",
    "                 pruning_threshold=0.001,\n",
    "                )\n",
    "\n",
    "# эту часть кода менять не нужно - здесь происходит отрисовка\n",
    "\n",
    "# выделяем получившиеся кластеры\n",
    "clusters = mc.get_clusters(res)\n",
    "\n",
    "# отрисовываем граф с результатами кластеризации\n",
    "mc.draw_graph(graph, clusters, pos=p, with_labels = False, node_size=30, edge_color=\"silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = mc.modularity(matrix = res, clusters = clusters)\n",
    "print('Modularity score = {:.5f}'.format(Q))\n",
    "print('Требуемое качество достигнуто' if Q > 0.798 else 'Требуемое качество не достигнуто')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
